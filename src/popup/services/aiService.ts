
import { GoogleGenerativeAI } from "@google/generative-ai";
import { SummaryMode, Clipping, AIModel } from "../types";

export const generateAIContent = async (
  mode: SummaryMode,
  clippings: Clipping[],
  customInstruction: string = "",
  apiKey: string,
  model: AIModel
): Promise<string> => {
  if (!apiKey) {
    throw new Error("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì •ì—ì„œ API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.");
  }

  // Use the requested model directly
  const effectiveModel = model as string;
  console.log(`[AI Logic] Using model: ${effectiveModel}`);

  // í…ìŠ¤íŠ¸ ì¡°í•© (ì¶œì²˜ ë° ì‹œê°„ ì •ë³´ í¬í•¨)
  const contentToAnalyze = clippings.map(c =>
    `[ë°œì·Œ ì›ë¬¸]: ${c.text}\n[ì¶œì²˜]: ${c.sourceUrl}\n[ìˆ˜ì§‘ ì‹œê°]: ${new Date(c.timestamp).toLocaleString()}`
  ).join("\n\n---\n\n");

  // ëª¨ë“œë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
  const inputSystemInstruction = getSystemInstruction(mode);

  // ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
  const userPrompt = `
    ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì›¹ì—ì„œ ìˆ˜ì§‘í•œ í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì…ë‹ˆë‹¤.
    
    ${contentToAnalyze}
    
    ---------------------------------------------------
    
    [ì‚¬ìš©ì ì¶”ê°€ ì§€ì‹œì‚¬í•­]
    ${customInstruction ? customInstruction : "íŠ¹ë³„í•œ ì¶”ê°€ ì§€ì‹œëŠ” ì—†ìŠµë‹ˆë‹¤. ìœ„ ì„¤ì •ëœ í˜ë¥´ì†Œë‚˜ì™€ í˜•ì‹ì— ì¶©ì‹¤í•´ ì£¼ì„¸ìš”."}
    
    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì„ íƒëœ ëª¨ë“œ(${mode})ì˜ í˜•ì‹ì— ë§ì¶° í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
  `;

  try {
    if (effectiveModel.startsWith('gemini')) {
      return await generateGeminiContent(apiKey, effectiveModel, inputSystemInstruction, userPrompt);
    } else if (effectiveModel.startsWith('gpt')) {
      return await generateOpenAIContent(apiKey, effectiveModel, inputSystemInstruction, userPrompt);
    } else if (effectiveModel.startsWith('claude')) {
      return await generateClaudeContent(apiKey, effectiveModel, inputSystemInstruction, userPrompt);
    } else {
      throw new Error("ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.");
    }
  } catch (error) {
    console.error("AI Generation Error:", error);

    // í• ë‹¹ëŸ‰ ì´ˆê³¼(429) ì—ëŸ¬ ì²˜ë¦¬
    const errorMsg = String(error);
    if (errorMsg.includes('429') || errorMsg.includes('Quota exceeded') || errorMsg.includes('quota')) {
      throw new Error("API í• ë‹¹ëŸ‰ì„ ëª¨ë‘ ì†Œëª¨í–ˆê±°ë‚˜ ì‚¬ìš©ì´ ì¼ì‹œì ìœ¼ë¡œ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ API í‚¤ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.");
    }

    throw new Error(`AI ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : errorMsg}`);
  }
};

const getSystemInstruction = (mode: SummaryMode): string => {
  const instructions = {
    [SummaryMode.REPORT]: `
      ë‹¹ì‹ ì€ ì „ë¬¸ ë¦¬ì„œì¹˜ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì œê³µëœ í…ìŠ¤íŠ¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ê³µì‹ ë³´ê³ ì„œ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.
      [í•„ìˆ˜ í˜•ì‹]
      1. ì œëª©: (í•µì‹¬ ë‚´ìš©ì„ ê´€í†µí•˜ëŠ” ì œëª©)
      2. ë°°ê²½: (ì´ ì£¼ì œê°€ ì™œ ì¤‘ìš”í•œì§€, ë¬¸ë§¥ ì„¤ëª…)
      3. ì£¼ìš” ë‚´ìš©/ë¬¸ì œ: (ë°œì·Œëœ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ë¶„ì„)
      4. í•´ê²°ë°©í–¥/ì œì–¸: (ë‚´ìš©ì— ê¸°ë°˜í•œ í†µì°°)
      5. ê²°ë¡ : (í•œ ì¤„ ìš”ì•½)
      6. ì°¸ê³ ìë£Œ: (ì›ë³¸ ë§í¬ ëª©ë¡)
      í†¤ì•¤ë§¤ë„ˆ: ê°ê´€ì , ë¶„ì„ì , ì „ë¬¸ì .
    `,
    [SummaryMode.EMAIL]: `
      ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ í…ìŠ¤íŠ¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì—…ë¬´ìš© ì´ë©”ì¼ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.
      [í•„ìˆ˜ í˜•ì‹]
      1. ì œëª©: (ìˆ˜ì‹ ìê°€ í´ë¦­í•˜ê³  ì‹¶ì€ ëª…í™•í•œ ì œëª©)
      2. ë„ì…ë¶€: (ì •ì¤‘í•œ ì¸ì‚¬ ë° ë©”ì¼ ëª©ì )
      3. í•µì‹¬ ìš”ì•½: (ë°œì·Œ ë‚´ìš©ì˜ ìš”ì  ì •ë¦¬ - ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ì‚¬ìš©)
      4. ìš”ì²­/ì œì•ˆ ì‚¬í•­: (ëª…í™•í•œ Action Item)
      5. ë§ºìŒë§: (ì¶”í›„ ì¼ì • ì–¸ê¸‰ ë° ì •ì¤‘í•œ ë§ˆë¬´ë¦¬)
      í†¤ì•¤ë§¤ë„ˆ: ì •ì¤‘í•¨, ëª…ë£Œí•¨, ë¹„ì¦ˆë‹ˆìŠ¤ ê²©ì‹.
    `,
    [SummaryMode.NOTION]: `
      ë‹¹ì‹ ì€ ì§€ì‹ ê´€ë¦¬(PKM) ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ í…ìŠ¤íŠ¸ë¥¼ ë…¸ì…˜(Notion)ì— ì €ì¥í•˜ê¸° ì¢‹ì€ êµ¬ì¡°í™”ëœ ë…¸íŠ¸ë¡œ ë³€í™˜í•˜ì„¸ìš”.
      [í•„ìˆ˜ í˜•ì‹ - ë§ˆí¬ë‹¤ìš´]
      # (ì§ê´€ì ì¸ ì œëª©)
      ## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
      (ë‚´ìš©ì˜ ë³¸ì§ˆì ì¸ ì˜ë¯¸ë‚˜ í†µì°° 1-2ë¬¸ì¥)
      ## ğŸ“ ìƒì„¸ ìš”ì•½
      - (ì£¼ìš” í¬ì¸íŠ¸ 1)
      - (ì£¼ìš” í¬ì¸íŠ¸ 2)
      ## âœ… Action Item / ì ìš©ì 
      - [ ] (ì‹¤ì²œ ê°€ëŠ¥í•œ í•­ëª© 1)
      > [ì¶œì²˜ ë° íƒœê·¸]
      > #íƒœê·¸1 #íƒœê·¸2
      í†¤ì•¤ë§¤ë„ˆ: ì§ê´€ì , êµ¬ì¡°ì , í•µì‹¬ ìœ„ì£¼.
    `,
    [SummaryMode.CARD]: `
      ë‹¹ì‹ ì€ ì½˜í…ì¸  íë ˆì´í„°ì…ë‹ˆë‹¤. ì†Œì…œ ë¯¸ë””ì–´(LinkedIn, Twitter)ë‚˜ ì¹´ë“œ ë‰´ìŠ¤ì— ì í•©í•œ í˜•íƒœë¡œ ìš”ì•½í•˜ì„¸ìš”.
      [í•„ìˆ˜ í˜•ì‹]
      1. ìºì¹˜í”„ë ˆì´ì¦ˆ (ì‹œì„ ì„ ë„ëŠ” í•œ ë¬¸ì¥)
      2. 3ì¤„ ìš”ì•½ (ì´ëª¨ì§€ í™œìš©)
      3. ì›ë¬¸ ë§í¬
      í†¤ì•¤ë§¤ë„ˆ: íŠ¸ë Œë””, ê°„ê²°í•¨, ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©.
    `
  };
  return instructions[mode];
};

// Gemini Implementation
const generateGeminiContent = async (apiKey: string, model: string, systemInstruction: string, prompt: string): Promise<string> => {
  const genAI = new GoogleGenerativeAI(apiKey);
  const generativeModel = genAI.getGenerativeModel({ model: model });

  const result = await generativeModel.generateContent([
    systemInstruction,
    prompt
  ]);
  const response = await result.response;
  return response.text();
};

// OpenAI Implementation
const generateOpenAIContent = async (apiKey: string, model: string, systemInstruction: string, prompt: string): Promise<string> => {
  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${apiKey}`
    },
    body: JSON.stringify({
      model: model,
      messages: [
        { role: "system", content: systemInstruction },
        { role: "user", content: prompt }
      ],
      temperature: 0.7
    })
  });

  if (!response.ok) {
    const errorData = await response.json();
    throw new Error(`OpenAI API Error: ${errorData.error?.message || response.statusText}`);
  }

  const data = await response.json();
  return data.choices[0]?.message?.content || "ë‚´ìš©ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.";
};

// Anthropic Implementation
const generateClaudeContent = async (apiKey: string, model: string, systemInstruction: string, prompt: string): Promise<string> => {
  // Anthropic API requires a proxy or strict CORS handling usually, but explicit permission in manifest might allow direct call from extension.
  // Note: Anthropic uses 'max_tokens' which is required.
  const response = await fetch("https://api.anthropic.com/v1/messages", {
    method: "POST",
    headers: {
      "x-api-key": apiKey,
      "anthropic-version": "2023-06-01",
      "content-type": "application/json",
      "dangerously-allow-browser": "true" // Required for client-side calls if not proxied
    },
    body: JSON.stringify({
      model: model,
      max_tokens: 4096,
      system: systemInstruction,
      messages: [
        { role: "user", content: prompt }
      ],
      temperature: 0.7
    })
  });

  if (!response.ok) {
    const errorData = await response.json();
    throw new Error(`Anthropic API Error: ${errorData.error?.message || response.statusText}`);
  }

  const data = await response.json();
  return data.content[0]?.text || "ë‚´ìš©ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.";
};
